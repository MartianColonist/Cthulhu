{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd5fefe3",
   "metadata": {},
   "source": [
    "## Running Excalibur on a Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For real world applications, one typically needs a cross section computed across a grid of temperatures and pressures. Such computations can be much more efficiently handled on a computing cluster, where each (P,T) pair can be assigned to a distributed 'job'.\n",
    "\n",
    "This tutorial describes how to run `excalibur` on a cluster, focusing on clusters managed by the common Slurm scheduling system.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "  **Note:**\n",
    "\n",
    "  Every computing cluster is special and has its own unique architecture. We strongly recommend reading the documentation for your local cluster before proceeding and adapting the code below accordingly.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running on a cluster involves two separate files:\n",
    "\n",
    "1. A Python file calling `excalibur` (similar to those you've seen in the previous tutorials).\n",
    "2. A shell script to distribute each pressure-temperature point to a different core."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45860f64",
   "metadata": {},
   "source": [
    "#### Python script in cluster mode\n",
    "\n",
    "Let's first create a python file to calculate cross sections for $\\mathrm{Fe}$, $\\mathrm{Ti}$, $\\mathrm{Mg}$, and $\\mathrm{Fe^{+}}$ all at once. When a user places `excalibur` in cluster mode (via ``cluster_run = True``) the code will use a single core for each pressure and temperature pair. \n",
    "\n",
    "In the example here, a core will first compute the $\\mathrm{Fe}$ cross section at a given (P, T), then continue to compute $\\mathrm{Ti}$ at the same (P, T) pair and so on. So each core will calculate 4 cross sections at a single (P, T) point and we will use a Slurm shell script to request enough cores to cover all the (P, T) points we desire cross sections for.\n",
    "\n",
    "Copy the code below into a .py file... how about `many_atoms_on_my_powerful_cluster.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#***** Example script to batch-run EXCALIBUR on a cluster *****#\n",
    "\n",
    "from excalibur.core import compute_cross_section\n",
    "\n",
    "species_neutral = ['Fe', 'Ti', 'Mg']   # Fe, Ti, and Mg (neutral atoms)\n",
    "species_ions = ['Fe']                  # Fe + (the ionization state is entered below)\n",
    "\n",
    "database = 'VALD'\n",
    "\n",
    "input_directory = '/PATH_TO_YOUR_LINE_LISTS/input/'      # Change this to point to your line list input folder\n",
    "\n",
    "P = [1.0e-6, 1.0e-5, 1.0e-4, 1.0e-3, 1.0e-2, 1.0e-1, 1.0e0, 1.0e1, 1.0e2]    # Pressure (bar)\n",
    "log_P = [-6.0, -5.0, -4.0, -3.0, -2.0, -1.0, 0.0, 1.0, 2.0]                  # log10 pressure\n",
    "T = [100.0, 200.0, 300.0, 400.0, 500.0, 600.0, 700.0, 800.0,                 # Temperature (K)\n",
    "     900.0, 1000.0, 1200.0, 1400.0, 1600.0, 1800.0, 2000.0,\n",
    "     2500.0, 3000.0, 3500.0]\n",
    "\n",
    "# Create cross section\n",
    "for i in range(len(species_neutral)):\n",
    "     compute_cross_section(database = database, species = species_neutral[i], \n",
    "                           pressure = P, temperature = T, S_cut = 1.0e-100,\n",
    "                           input_dir = input_directory, ionization_state = 1,\n",
    "                           nu_out_min = 200, nu_out_max = 40000, dnu_out = 0.01,\n",
    "                           verbose = False, N_cores = 1, cluster_run = True)        # The last argument must be True for a cluster run!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slurm shell script\n",
    "\n",
    "Now we need to create a shell script to assign a core to each (P, T) pair.\n",
    "\n",
    "From looking at the Python script above, we have 9 pressures and 18 temperatures, for a total of 162 (P, T) pairs. So we will create a shell script to submit 162 jobs, one for each (P, T) point, with a single core being assigned to each job. Each job will run `excalibur` from the terminal via the following commands:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e472005",
   "metadata": {},
   "source": [
    "  ```\n",
    "  python -u many_atoms_on_my_powerful_cluster.py 0\n",
    "  python -u many_atoms_on_my_powerful_cluster.py 1\n",
    "  python -u many_atoms_on_my_powerful_cluster.py 2\n",
    "  .\n",
    "  .\n",
    "  .\n",
    "  python -u many_atoms_on_my_powerful_cluster.py 161\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd563a1",
   "metadata": {},
   "source": [
    "Where '0' here denotes the first (P, T) pair (P[0], T[0]) and '161' denotes the final (P, T) pair (P[8], T[17]).\n",
    "\n",
    "To accomplish this, copy the code below into a shell script (.sh). We'll call it `my_ultimate_shell_script.sh`. \n",
    "\n",
    "You should also make a folder called `logs` in the same folder to store the terminal output from each job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b6ee0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Job name for the group\n",
    "JOB_NAME=\"atoms\"\n",
    "\n",
    "for i in {0..161}; do                     # Loops over the 162 jobs\n",
    "    srun \\\n",
    "        --account=YOUR_USER_ACCOUNT \\             # Your user account on your cluster (or which account will be charged)\n",
    "        --partition=standard \\                    # Your cluster may have a different name for the default partition\n",
    "        --nodes=1 \\\n",
    "        --cpus-per-task=1 \\                       # We only need one core per job, since\n",
    "        --tasks-per-node=1 \\\n",
    "        --mem=100G \\                              # Reserving 100 GB of RAM (less is probably fine)\n",
    "        --time=0-01:00:00 \\                       # Max runtime of 1 hour (atoms will take seconds, large molecules could need days)\n",
    "        --output=./logs/${JOB_NAME}.$i.out \\      # In a directory called 'logs' (make one!), write the terminal output\n",
    "        --error=./logs/${JOB_NAME}.$i.err \\       # Write any error messages into a seperate file\n",
    "        --job-name=$JOB_NAME \\\n",
    "        python -u /PATH/TO/YOUR/CODE/many_atoms_on_my_powerful_clutster.py $i &     # Path to the Python file above\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You run this shell script simply by:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fff99bd",
   "metadata": {},
   "source": [
    "  ```\n",
    "  ./my_ultimate_shell_script.sh\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779d787d",
   "metadata": {},
   "source": [
    "Congratulations, you have just unlocked the power of calculating cross sections in parallel on 162 cores! ðŸŽ‰"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
